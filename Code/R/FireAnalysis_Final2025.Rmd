---
title: "FIRE Campus Speech Analysis - 2025"
author: "DGK"
date: "Q3 2025"
output:
  pdf_document:
    toc: true
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, fig.width = 10, fig.height = 6)
```

# 1. Setup and Data Loading

## 1.1 Load Required Libraries
```{r libraries}
library(tidyverse)
library(ggplot2)
library(corrplot)
library(car)
```

## 1.2 Load Labeled Data
```{r load_data}
# Load the labeled dataset
labeled_file <- "/Users/dgkamper/Library/CloudStorage/GoogleDrive-dgkamper@gmail.com/My Drive/DGK Lab/Collaborations/Haselton Lab/DGK Lab; Haselton Lab - FIRE Dataset Analysis/Data/2025 CFSR Labeled, Questions_Edit.csv"

# Load the numeric dataset
numeric_file <- "/Users/dgkamper/Library/CloudStorage/GoogleDrive-dgkamper@gmail.com/My Drive/DGK Lab/Collaborations/Haselton Lab/DGK Lab; Haselton Lab - FIRE Dataset Analysis/Data/2025 CFSR Numeric, Public.csv"

# Load the dataset
df_labeled <- read.csv(labeled_file, na.strings = c("", "NA", "-99"), stringsAsFactors = TRUE)
df_numeric <- read.csv(numeric_file, na.strings = c("", "NA", "-99"), stringsAsFactors = TRUE)

# Basic data inspection
cat("Dataset dimensions:", dim(df_labeled), "\n")
cat("Number of variables:", ncol(df_labeled), "\n")
cat("Number of observations:", nrow(df_labeled), "\n")

# Check the structure of key variables
cat("\nKey variable types:\n")
key_vars <- c("selfcensor", "scstdnts", "scprofs", "scclass", "shoutdown", "block", "violence", "ideo")
for(var in key_vars) {
  if(var %in% names(df_labeled)) {
    cat(var, ":", class(df_labeled[[var]]), "\n")
    if(is.factor(df_labeled[[var]])) {
      cat("  Levels:", paste(levels(df_labeled[[var]]), collapse = ", "), "\n")
    }
  }
}
```

# 2. Data Preprocessing

## 2.1 Convert Key Variables to Numeric for Analysis
```{r convert_variables}
cat("=== CONVERTING LABELED RESPONSES TO NUMERIC FOR ANALYSIS ===\n\n")

# Convert self-censorship questions to numeric (assuming standard Likert scale)
# We'll need to see the actual levels first
selfcensor_vars <- c("selfcensor", "scstdnts", "scprofs", "scclass")

for(var in selfcensor_vars) {
  if(var %in% names(df_labeled) && is.factor(df_labeled[[var]])) {
    cat("Levels for", var, ":\n")
    print(table(df_labeled[[var]], useNA = "ifany"))
    cat("\n")
  }
}

# Convert protest tolerance questions
protest_vars <- c("shoutdown", "block", "violence")

for(var in protest_vars) {
  if(var %in% names(df_labeled) && is.factor(df_labeled[[var]])) {
    cat("Levels for", var, ":\n")
    print(table(df_labeled[[var]], useNA = "ifany"))
    cat("\n")
  }
}

# Convert ideology
if("ideo" %in% names(df_labeled)) {
  cat("Ideology levels:\n")
  print(table(df_labeled$ideo, useNA = "ifany"))
}
```

## 2.2 Create Numeric Versions
```{r create_numeric}
cat("=== CREATING NUMERIC VERSIONS FOR ANALYSIS ===\n\n")

# Create working dataset
df_analysis <- df_labeled

# Function to convert ordered factors to numeric while preserving order
convert_to_numeric_ordered <- function(x, reverse = FALSE) {
  if(is.factor(x)) {
    numeric_values <- as.numeric(x)
    if(reverse) {
      max_val <- max(numeric_values, na.rm = TRUE)
      numeric_values <- (max_val + 1) - numeric_values
    }
    return(numeric_values)
  } else {
    return(as.numeric(x))
  }
}

# Convert self-censorship variables (higher = more self-censorship)
# Note: We may need to reverse code depending on how the questions are worded
df_analysis$selfcensor_num <- convert_to_numeric_ordered(df_analysis$selfcensor)
df_analysis$scstdnts_num <- convert_to_numeric_ordered(df_analysis$scstdnts)
df_analysis$scprofs_num <- convert_to_numeric_ordered(df_analysis$scprofs)
df_analysis$scclass_num <- convert_to_numeric_ordered(df_analysis$scclass)

# Convert protest tolerance variables (higher = more tolerant of protest tactics)
df_analysis$shoutdown_num <- convert_to_numeric_ordered(df_analysis$shoutdown)
df_analysis$block_num <- convert_to_numeric_ordered(df_analysis$block)
df_analysis$violence_num <- convert_to_numeric_ordered(df_analysis$violence)

# Convert ideology to ordered factor
if("ideo" %in% names(df_analysis)) {
  # Create a clean ideology factor
  df_analysis$ideology_clean <- factor(df_analysis$ideo, ordered = TRUE)
}

cat("Numeric conversion completed!\n")

# Check data availability
selfcensor_numeric <- c("selfcensor_num", "scstdnts_num", "scprofs_num", "scclass_num")
protest_numeric <- c("shoutdown_num", "block_num", "violence_num")

cat("\nData availability for numeric versions:\n")
for(var in c(selfcensor_numeric, protest_numeric, "ideology_clean")) {
  if(var %in% names(df_analysis)) {
    missing <- sum(is.na(df_analysis[[var]]))
    total <- nrow(df_analysis)
    cat(sprintf("%-20s: %6d non-missing out of %6d (%5.1f%%)\n", 
                var, total - missing, total, 100*(total-missing)/total))
  }
}
```

# 3. Core Research Question: Individual Question Correlations

## 3.1 Self-Censorship vs Protest Tolerance Correlations
```{r core_correlations}
cat("=== INDIVIDUAL QUESTION CORRELATIONS ===\n\n")
cat("Research Question: How do individual self-censorship questions relate to individual protest tolerance questions?\n\n")

# Create correlation matrix between individual questions
selfcensor_questions <- c("selfcensor_num", "scstdnts_num", "scprofs_num", "scclass_num")
protest_questions <- c("shoutdown_num", "block_num", "violence_num")

selfcensor_names <- c("General Self-Censorship", "With Students", "With Professors", "In Classroom")
protest_names <- c("Shouting Down", "Blocking", "Violence")

# Detailed correlation analysis
correlation_results <- data.frame(
  Self_Censorship_Question = character(),
  Protest_Question = character(),
  Correlation = numeric(),
  P_Value = numeric(),
  N = numeric(),
  stringsAsFactors = FALSE
)

cat("DETAILED CORRELATION ANALYSIS:\n")
for(i in 1:length(selfcensor_questions)) {
  for(j in 1:length(protest_questions)) {
    sc_var <- selfcensor_questions[i]
    protest_var <- protest_questions[j]
    
    if(sc_var %in% names(df_analysis) && protest_var %in% names(df_analysis)) {
      complete_data <- df_analysis[!is.na(df_analysis[[sc_var]]) & 
                                  !is.na(df_analysis[[protest_var]]), ]
      
      if(nrow(complete_data) > 100) {
        cor_test <- cor.test(complete_data[[sc_var]], complete_data[[protest_var]])
        
        cat(sprintf("%-25s vs %-15s: r = %6.3f, p = %s, N = %d\n", 
                    selfcensor_names[i], protest_names[j],
                    cor_test$estimate, format.pval(cor_test$p.value), nrow(complete_data)))
        
        correlation_results <- rbind(correlation_results, data.frame(
          Self_Censorship_Question = selfcensor_names[i],
          Protest_Question = protest_names[j],
          Correlation = round(cor_test$estimate, 3),
          P_Value = cor_test$p.value,
          N = nrow(complete_data),
          stringsAsFactors = FALSE
        ))
      }
    }
  }
}

# Create correlation matrix for visualization
if(nrow(correlation_results) > 0) {
  correlation_wide <- reshape(correlation_results[, c("Self_Censorship_Question", "Protest_Question", "Correlation")], 
                             direction = "wide", 
                             idvar = "Self_Censorship_Question", 
                             timevar = "Protest_Question")
  
  names(correlation_wide) <- gsub("Correlation\\.", "", names(correlation_wide))
  rownames(correlation_wide) <- correlation_wide$Self_Censorship_Question
  cor_mat <- as.matrix(correlation_wide[, -1])
  
  if(require(corrplot, quietly = TRUE)) {
    corrplot(cor_mat, method = "color", addCoef.col = "black", 
             title = "Self-Censorship vs Protest Tolerance: Individual Questions",
             mar = c(0,0,2,0))
  }
}
```

# 4. Individual Question Analysis by Political Ideology

## 4.1 Self-Censorship Questions by Ideology
```{r selfcensor_by_ideology}
cat("=== SELF-CENSORSHIP BY POLITICAL IDEOLOGY (INDIVIDUAL QUESTIONS) ===\n\n")

for(i in 1:length(selfcensor_questions)) {
  var <- selfcensor_questions[i]
  name <- selfcensor_names[i]
  
  if(var %in% names(df_analysis)) {
    ideology_data <- df_analysis[!is.na(df_analysis[[var]]) & !is.na(df_analysis$ideology_clean), ]
    
    if(nrow(ideology_data) > 500) {
      cat("=== ", name, " ===\n")
      
      # ANOVA
      anova_result <- aov(get(var) ~ ideology_clean, data = ideology_data)
      cat("ANOVA Results:\n")
      print(summary(anova_result))
      
      # Summary statistics by ideology
      ideology_summary <- ideology_data %>%
        group_by(ideology_clean) %>%
        summarise(
          N = n(),
          Mean = round(mean(.data[[var]], na.rm = TRUE), 2),
          SD = round(sd(.data[[var]], na.rm = TRUE), 2),
          .groups = "drop"
        )
      print(ideology_summary)
      
      # Visualization
      ggplot(ideology_data, aes(x = ideology_clean, y = .data[[var]], fill = ideology_clean)) +
        geom_boxplot() +
        labs(title = paste(name, "by Political Ideology"),
             subtitle = paste("N =", nrow(ideology_data), "students with complete data"),
             x = "Political Ideology",
             y = paste(name, "Score")) +
        theme_minimal() +
        theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
        guides(fill = "none")
      
      cat("\n")
    }
  }
}
```

## 4.2 Protest Tolerance Questions by Ideology
```{r protest_by_ideology}
cat("=== PROTEST TOLERANCE BY POLITICAL IDEOLOGY (INDIVIDUAL QUESTIONS) ===\n\n")

for(i in 1:length(protest_questions)) {
  var <- protest_questions[i]
  name <- protest_names[i]
  
  if(var %in% names(df_analysis)) {
    ideology_data <- df_analysis[!is.na(df_analysis[[var]]) & !is.na(df_analysis$ideology_clean), ]
    
    if(nrow(ideology_data) > 500) {
      cat("=== ", name, " Tolerance ===\n")
      
      # ANOVA
      anova_result <- aov(get(var) ~ ideology_clean, data = ideology_data)
      cat("ANOVA Results:\n")
      print(summary(anova_result))
      
      # Summary statistics by ideology
      ideology_summary <- ideology_data %>%
        group_by(ideology_clean) %>%
        summarise(
          N = n(),
          Mean = round(mean(.data[[var]], na.rm = TRUE), 2),
          SD = round(sd(.data[[var]], na.rm = TRUE), 2),
          .groups = "drop"
        )
      print(ideology_summary)
      
      # Visualization
      ggplot(ideology_data, aes(x = ideology_clean, y = .data[[var]], fill = ideology_clean)) +
        geom_boxplot() +
        labs(title = paste("Tolerance for", name, "by Political Ideology"),
             subtitle = paste("N =", nrow(ideology_data), "students with complete data"),
             x = "Political Ideology",
             y = paste(name, "Tolerance Score")) +
        theme_minimal() +
        theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
        guides(fill = "none")
      
      cat("\n")
    }
  }
}
```

# 5. Individual Speaker Topics Analysis

## 5.1 Speaker Tolerance by Topic and Ideology
```{r speaker_analysis}
cat("=== INDIVIDUAL SPEAKER TOPICS ANALYSIS ===\n\n")

# Find speaker variables
speaker_vars <- c("spktrans", "spkabortion", "spkblm", "spkchurch", "spkpolice", "spkchildren", "spkgaza", "spkpalestine")
speaker_names <- c("Transgender Rights", "Abortion", "Black Lives Matter", "Religious/Church", 
                   "Police", "Children/Family", "Gaza", "Palestine")

for(i in 1:length(speaker_vars)) {
  var <- speaker_vars[i]
  name <- speaker_names[i]
  
  if(var %in% names(df_analysis)) {
    cat("=== ", name, " Speaker ===\n")
    
    # Convert to numeric if factor
    if(is.factor(df_analysis[[var]])) {
      df_analysis[[paste0(var, "_num")]] <- convert_to_numeric_ordered(df_analysis[[var]])
      var_num <- paste0(var, "_num")
    } else {
      var_num <- var
    }
    
    # Distribution
    cat("Distribution:\n")
    print(table(df_analysis[[var]], useNA = "ifany"))
    
    # Analysis by ideology
    ideology_data <- df_analysis[!is.na(df_analysis[[var_num]]) & !is.na(df_analysis$ideology_clean), ]
    
    if(nrow(ideology_data) > 500) {
      # ANOVA
      anova_result <- aov(get(var_num) ~ ideology_clean, data = ideology_data)
      cat("\nANOVA by Political Ideology:\n")
      print(summary(anova_result))
      
      # Summary statistics
      ideology_summary <- ideology_data %>%
        group_by(ideology_clean) %>%
        summarise(
          N = n(),
          Mean = round(mean(.data[[var_num]], na.rm = TRUE), 2),
          SD = round(sd(.data[[var_num]], na.rm = TRUE), 2),
          .groups = "drop"
        )
      print(ideology_summary)
      
      # Visualization
      ggplot(ideology_data, aes(x = ideology_clean, y = .data[[var_num]], fill = ideology_clean)) +
        geom_boxplot() +
        labs(title = paste("Tolerance for", name, "Speaker by Political Ideology"),
             subtitle = paste("N =", nrow(ideology_data), "students"),
             x = "Political Ideology",
             y = "Speaker Tolerance") +
        theme_minimal() +
        theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
        guides(fill = "none")
    }
    cat("\n\n")
  }
}
```

# 6. Mental Health Analysis (Individual Questions)

## 6.1 Individual Mental Health Variables
```{r mental_health_individual}
cat("=== INDIVIDUAL MENTAL HEALTH ANALYSIS ===\n\n")

# Mental health variables
mh_vars <- c("anxious", "lonely", "depressed", "stressed")
mh_names <- c("Anxiety", "Loneliness", "Depression", "Stress")

for(i in 1:length(mh_vars)) {
  var <- mh_vars[i]
  name <- mh_names[i]
  
  if(var %in% names(df_analysis)) {
    cat("=== ", name, " Analysis ===\n")
    
    # Convert to numeric if needed
    if(is.factor(df_analysis[[var]])) {
      df_analysis[[paste0(var, "_num")]] <- convert_to_numeric_ordered(df_analysis[[var]])
      var_num <- paste0(var, "_num")
    } else {
      var_num <- var
    }
    
    # Check data availability
    non_missing <- sum(!is.na(df_analysis[[var_num]]))
    cat("Sample size:", non_missing, "out of", nrow(df_analysis), "\n")
    
    if(non_missing > 100) {
      # Distribution
      cat("Distribution:\n")
      print(table(df_analysis[[var]], useNA = "ifany"))
      
      # Correlations with each self-censorship question individually
      cat("\nCorrelations with self-censorship questions:\n")
      for(j in 1:length(selfcensor_questions)) {
        sc_var <- selfcensor_questions[j]
        sc_name <- selfcensor_names[j]
        
        if(sc_var %in% names(df_analysis)) {
          complete_data <- df_analysis[!is.na(df_analysis[[var_num]]) & !is.na(df_analysis[[sc_var]]), ]
          
          if(nrow(complete_data) > 50) {
            cor_test <- cor.test(complete_data[[var_num]], complete_data[[sc_var]])
            cat(sprintf("  %-25s: r = %6.3f, p = %s, N = %d\n", 
                        sc_name, cor_test$estimate, 
                        format.pval(cor_test$p.value), nrow(complete_data)))
          }
        }
      }
      
      # Analysis by political ideology
      ideology_data <- df_analysis[!is.na(df_analysis[[var_num]]) & !is.na(df_analysis$ideology_clean), ]
      
      if(nrow(ideology_data) > 100) {
        cat("\nANOVA by Political Ideology:\n")
        anova_result <- aov(get(var_num) ~ ideology_clean, data = ideology_data)
        print(summary(anova_result))
        
        # Visualization
        ggplot(ideology_data, aes(x = ideology_clean, y = .data[[var_num]], fill = ideology_clean)) +
          geom_boxplot() +
          labs(title = paste(name, "by Political Ideology"),
               x = "Political Ideology",
               y = paste(name, "Score")) +
          theme_minimal() +
          theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
          guides(fill = "none")
      }
    }
    cat("\n\n")
  }
}
```

# 7. Religious and Group Funding Analysis

## 7.1 Religious Attendance Analysis
```{r religious_analysis}
cat("=== RELIGIOUS ATTENDANCE ANALYSIS ===\n\n")

if("religattend" %in% names(df_analysis)) {
  # Convert to numeric if needed
  if(is.factor(df_analysis$religattend)) {
    df_analysis$religattend_num <- convert_to_numeric_ordered(df_analysis$religattend)
  } else {
    df_analysis$religattend_num <- as.numeric(df_analysis$religattend)
  }
  
  # Distribution
  cat("Religious attendance distribution:\n")
  print(table(df_analysis$religattend, useNA = "ifany"))
  
  # Correlations with each self-censorship question
  cat("\nCorrelations with self-censorship questions:\n")
  for(j in 1:length(selfcensor_questions)) {
    sc_var <- selfcensor_questions[j]
    sc_name <- selfcensor_names[j]
    
    if(sc_var %in% names(df_analysis)) {
      complete_data <- df_analysis[!is.na(df_analysis$religattend_num) & !is.na(df_analysis[[sc_var]]), ]
      
      if(nrow(complete_data) > 100) {
        cor_test <- cor.test(complete_data$religattend_num, complete_data[[sc_var]])
        cat(sprintf("  %-25s: r = %6.3f, p = %s, N = %d\n", 
                    sc_name, cor_test$estimate, 
                    format.pval(cor_test$p.value), nrow(complete_data)))
      }
    }
  }
  
  # Analysis by political ideology
  ideology_data <- df_analysis[!is.na(df_analysis$religattend_num) & !is.na(df_analysis$ideology_clean), ]
  
  if(nrow(ideology_data) > 500) {
    cat("\nANOVA: Religious Attendance by Political Ideology\n")
    anova_result <- aov(religattend_num ~ ideology_clean, data = ideology_data)
    print(summary(anova_result))
    
    # Visualization
    ggplot(ideology_data, aes(x = ideology_clean, y = religattend_num, fill = ideology_clean)) +
      geom_boxplot() +
      labs(title = "Religious Attendance by Political Ideology",
           x = "Political Ideology",
           y = "Religious Attendance") +
      theme_minimal() +
      theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
      guides(fill = "none")
  }
}
```

# 8. Other Critical Analyses

## 8.1 Religious Affiliation Analysis
```{r religious_affiliation}
cat("=== RELIGIOUS AFFILIATION ANALYSIS ===\n\n")

if("religion" %in% names(df_analysis)) {
  cat("Religious affiliation distribution:\n")
  print(table(df_analysis$religion, useNA = "ifany"))
  
  # Convert to factor with meaningful labels if needed
  if(is.numeric(df_analysis$religion) || length(levels(df_analysis$religion)) > 15) {
    # Use the coding from the conversation transcript
    df_analysis$religion_clean <- factor(df_analysis$religion, 
                                        levels = 1:13,
                                        labels = c("Protestant", "Catholic", "Mormon", "Orthodox", 
                                                  "Jewish", "Muslim", "Atheist", "Agnostic", 
                                                  "Nothing", "Christian", "Buddhist", "Hindu", "Other"))
  } else {
    df_analysis$religion_clean <- df_analysis$religion
  }
  
  cat("\nCleaned religious affiliation distribution:\n")
  print(table(df_analysis$religion_clean, useNA = "ifany"))
  
  # Analysis by political ideology
  religion_ideology_data <- df_analysis[!is.na(df_analysis$religion_clean) & !is.na(df_analysis$ideology_clean), ]
  
  if(nrow(religion_ideology_data) > 1000) {
    cat("\nCross-tabulation: Religious Affiliation × Political Ideology\n")
    religion_ideology_table <- table(religion_ideology_data$religion_clean, religion_ideology_data$ideology_clean)
    print(religion_ideology_table)
    
    # Chi-square test
    chi_test <- chisq.test(religion_ideology_table)
    cat("\nChi-square test: X-squared =", round(chi_test$statistic, 3), 
        ", p =", format.pval(chi_test$p.value), "\n")
    
    # Visualization
    religion_ideology_prop <- religion_ideology_data %>%
      group_by(religion_clean, ideology_clean) %>%
      summarise(count = n(), .groups = "drop") %>%
      group_by(religion_clean) %>%
      mutate(prop = count / sum(count))
    
    ggplot(religion_ideology_prop, aes(x = religion_clean, y = prop, fill = ideology_clean)) +
      geom_col(position = "stack") +
      labs(title = "Political Ideology Distribution by Religious Affiliation",
           x = "Religious Affiliation",
           y = "Proportion",
           fill = "Political Ideology") +
      theme_minimal() +
      theme(axis.text.x = element_text(angle = 45, hjust = 1))
  }
  
  # Self-censorship by religious affiliation
  religion_sc_data <- df_analysis[!is.na(df_analysis$religion_clean), ]
  
  if(nrow(religion_sc_data) > 1000) {
    cat("\nSelf-censorship by religious affiliation:\n")
    
    for(j in 1:length(selfcensor_questions)) {
      sc_var <- selfcensor_questions[j]
      sc_name <- selfcensor_names[j]
      
      if(sc_var %in% names(df_analysis)) {
        complete_data <- religion_sc_data[!is.na(religion_sc_data[[sc_var]]), ]
        
        if(nrow(complete_data) > 500) {
          cat("\n", sc_name, "by Religious Affiliation:\n")
          
          # ANOVA
          anova_result <- aov(get(sc_var) ~ religion_clean, data = complete_data)
          print(summary(anova_result))
          
          # Summary statistics for major religious groups only
          major_religions <- names(sort(table(complete_data$religion_clean), decreasing = TRUE)[1:6])
          major_relig_data <- complete_data[complete_data$religion_clean %in% major_religions, ]
          
          if(nrow(major_relig_data) > 300) {
            relig_summary <- major_relig_data %>%
              group_by(religion_clean) %>%
              summarise(
                N = n(),
                Mean = round(mean(.data[[sc_var]], na.rm = TRUE), 2),
                SD = round(sd(.data[[sc_var]], na.rm = TRUE), 2),
                .groups = "drop"
              )
            print(relig_summary)
          }
        }
      }
    }
  }
}
```

## 8.2 Graduation Year and Cohort Effects
```{r gradyear_analysis}
cat("=== GRADUATION YEAR AND COHORT EFFECTS ===\n\n")

if("gradyear" %in% names(df_analysis)) {
  cat("Graduation year distribution:\n")
  print(table(df_analysis$gradyear, useNA = "ifany"))
  
  # Convert to meaningful labels
  if(is.numeric(df_analysis$gradyear)) {
    df_analysis$class_year <- factor(df_analysis$gradyear,
                                    levels = sort(unique(df_analysis$gradyear), na.last = TRUE),
                                    labels = paste("Class of", sort(unique(df_analysis$gradyear), na.last = TRUE)))
  } else {
    df_analysis$class_year <- df_analysis$gradyear
  }
  
  # Self-censorship by graduation year
  gradyear_data <- df_analysis[!is.na(df_analysis$class_year), ]
  
  if(nrow(gradyear_data) > 1000) {
    cat("\nSelf-censorship patterns by graduation year:\n")
    
    for(j in 1:length(selfcensor_questions)) {
      sc_var <- selfcensor_questions[j]
      sc_name <- selfcensor_names[j]
      
      if(sc_var %in% names(df_analysis)) {
        complete_data <- gradyear_data[!is.na(gradyear_data[[sc_var]]), ]
        
        if(nrow(complete_data) > 500) {
          cat("\n", sc_name, "by Graduation Year:\n")
          
          # ANOVA
          anova_result <- aov(get(sc_var) ~ class_year, data = complete_data)
          print(summary(anova_result))
          
          # Summary statistics
          gradyear_summary <- complete_data %>%
            group_by(class_year) %>%
            summarise(
              N = n(),
              Mean = round(mean(.data[[sc_var]], na.rm = TRUE), 2),
              SD = round(sd(.data[[sc_var]], na.rm = TRUE), 2),
              .groups = "drop"
            )
          print(gradyear_summary)
          
          # Visualization for general self-censorship
          if(j == 1) {
            ggplot(complete_data, aes(x = class_year, y = .data[[sc_var]], fill = class_year)) +
              geom_boxplot() +
              labs(title = "General Self-Censorship by Graduation Year",
                   x = "Graduation Year",
                   y = "Self-Censorship Score") +
              theme_minimal() +
              theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
              guides(fill = "none")
          }
        }
      }
    }
  }
}
```

## 8.3 Geographic and School Type Analysis
```{r geographic_analysis}
cat("=== GEOGRAPHIC AND SCHOOL TYPE ANALYSIS ===\n\n")

# State analysis
if("state" %in% names(df_analysis)) {
  cat("State distribution (top 10):\n")
  state_table <- sort(table(df_analysis$state), decreasing = TRUE)
  print(head(state_table, 10))
  
  # Regional analysis if we have enough states
  if(length(state_table) > 10) {
    # Create simplified regional categories for major states
    df_analysis$region <- case_when(
      df_analysis$state %in% c("California", "Oregon", "Washington", "Hawaii", "Alaska") ~ "West Coast",
      df_analysis$state %in% c("Colorado", "Idaho", "Wyoming", "Montana", "Utah") ~ "Mountain West",
      df_analysis$state %in% c("Arizona", "New Mexico", "Nevada") ~ "Southwest",
      df_analysis$state %in% c("New York", "Massachusetts", "Connecticut", "New Jersey", "Pennsylvania", "District of Columbia", "Delaware", "Rhode                               Island", "Vermont", "New Hampshire", "Maine", "Maryland") ~ "Northeast",
      df_analysis$state %in% c("Texas", "Florida", "Georgia", "North Carolina", "South Carolina", "Tennessee", "West Virginia", "Virginia", "Alabama", "Mississippi", "Louisiana", "Kentucky", "Oklahoma", "Arkansas") ~ "South",
      df_analysis$state %in% c("Illinois", "Ohio", "Michigan", "Indiana", "Wisconsin", "Iowa", "Minnesota", "Nebraska", "South Dakota", "North Dakota", "Kansas", "Missouri") ~ "Midwest",
      TRUE ~ "Other"
    )
    
    cat("\nRegional distribution:\n")
    print(table(df_analysis$region, useNA = "ifany"))
    
    # Self-censorship by region
    region_data <- df_analysis[!is.na(df_analysis$region) & df_analysis$region != "Other", ]
    
    if(nrow(region_data) > 1000) {
      cat("\nGeneral self-censorship by region:\n")
      
      if("selfcensor_num" %in% names(df_analysis)) {
        complete_data <- region_data[!is.na(region_data$selfcensor_num), ]
        
        if(nrow(complete_data) > 500) {
          # ANOVA
          anova_result <- aov(selfcensor_num ~ region, data = complete_data)
          print(summary(anova_result))
          
          # Summary statistics
          region_summary <- complete_data %>%
            group_by(region) %>%
            summarise(
              N = n(),
              Mean = round(mean(selfcensor_num, na.rm = TRUE), 2),
              SD = round(sd(selfcensor_num, na.rm = TRUE), 2),
              .groups = "drop"
            )
          print(region_summary)
        }
      }
    }
  }
}

# Institution type analysis
if("insttype" %in% names(df_analysis)) {
  cat("\nInstitution type distribution:\n")
  print(table(df_analysis$insttype, useNA = "ifany"))
  
  # Self-censorship by institution type
  insttype_data <- df_analysis[!is.na(df_analysis$insttype), ]
  
  if(nrow(insttype_data) > 1000 && "selfcensor_num" %in% names(df_analysis)) {
    complete_data <- insttype_data[!is.na(insttype_data$selfcensor_num), ]
    
    if(nrow(complete_data) > 500) {
      cat("\nGeneral self-censorship by institution type:\n")
      
      # ANOVA
      anova_result <- aov(selfcensor_num ~ insttype, data = complete_data)
      print(summary(anova_result))
      
      # Summary statistics
      insttype_summary <- complete_data %>%
        group_by(insttype) %>%
        summarise(
          N = n(),
          Mean = round(mean(selfcensor_num, na.rm = TRUE), 2),
          SD = round(sd(selfcensor_num, na.rm = TRUE), 2),
          .groups = "drop"
        )
      print(insttype_summary)
    }
  }
}
```

## 8.4 Socioeconomic Status Analysis
```{r ses_analysis}
cat("=== SOCIOECONOMIC STATUS ANALYSIS ===\n\n")

if("ses" %in% names(df_analysis)) {
  cat("SES distribution:\n")
  print(table(df_analysis$ses, useNA = "ifany"))
  
  # Convert to meaningful factor if needed
  if(is.numeric(df_analysis$ses) || is.character(df_analysis$ses)) {
    # Assuming SES is coded as income categories or similar
    df_analysis$ses_clean <- as.factor(df_analysis$ses)
  } else {
    df_analysis$ses_clean <- df_analysis$ses
  }
  
  # Self-censorship by SES
  ses_data <- df_analysis[!is.na(df_analysis$ses_clean), ]
  
  if(nrow(ses_data) > 1000) {
    cat("\nSelf-censorship by socioeconomic status:\n")
    
    for(j in 1:length(selfcensor_questions)) {
      sc_var <- selfcensor_questions[j]
      sc_name <- selfcensor_names[j]
      
      if(sc_var %in% names(df_analysis)) {
        complete_data <- ses_data[!is.na(ses_data[[sc_var]]), ]
        
        if(nrow(complete_data) > 500) {
          cat("\n", sc_name, "by SES:\n")
          
          # ANOVA
          anova_result <- aov(get(sc_var) ~ ses_clean, data = complete_data)
          print(summary(anova_result))
          
          # Summary statistics (show only if not too many categories)
          if(length(levels(complete_data$ses_clean)) <= 8) {
            ses_summary <- complete_data %>%
              group_by(ses_clean) %>%
              summarise(
                N = n(),
                Mean = round(mean(.data[[sc_var]], na.rm = TRUE), 2),
                SD = round(sd(.data[[sc_var]], na.rm = TRUE), 2),
                .groups = "drop"
              )
            print(ses_summary)
          }
        }
      }
    }
  }
}
```

# 9. Alliance Theory: Testing Group-Based Political Preferences

## 9.1 Variable Encoding

```{r variable_encoding}
cat("=== USING NUMERIC DATA FOR GROUP FUNDING ANALYSIS ===\n\n")

# All group funding variables available
group_funding_vars <- c("asiangrps", "blkgrps", "hispgrps", "greekgrps", "lgbtqgrps",
                       "christgrps", "jewgrps", "islamgrps", "hindugrps", "atheistgrps",
                       "gopgrps", "demgrps", "consgrps", "libgrps", "blmgrps",
                       "israelgrps", "palestinegrps")

# Check numeric coding in the numeric dataset
cat("Checking numeric coding of group funding variables:\n")
for(var in group_funding_vars[1:17]) {
  if(var %in% names(df_numeric)) {
    cat("\nDistribution of", var, "(numeric):\n")
    print(table(df_numeric[[var]], useNA = "ifany"))
  }
}

# The numeric data shows:
# 1 = Should be able to register and receive student fees (SUPPORT)
# 0 = Should not be able to register and receive student fees (OPPOSE)
# So we don't need to recode - just use directly!

cat("\nCreating support variables directly from numeric data:\n")

# Simply copy the numeric variables as support variables - NO RECODING NEEDED!
for(var in group_funding_vars) {
  if(var %in% names(df_numeric)) {
    support_var <- paste0(var, "_support")
    
    # Create a mapping dataframe
    temp_mapping <- df_numeric[, c("idhash", var)]
    names(temp_mapping)[2] <- support_var
    
    # The numeric data is already correctly coded (1=support, 0=oppose)
    # Just copy it directly!
    
    # Merge with df_analysis by idhash
    df_analysis <- merge(df_analysis, temp_mapping, by = "idhash", all.x = TRUE)
  }
}

# Verify the coding worked
cat("\nVerification - Support variables:\n")
if("christgrps_support" %in% names(df_analysis)) {
  cat("Christian groups support distribution:\n")
  print(table(df_analysis$christgrps_support, useNA = "ifany"))
  
  cat("\nSupport rate for Christian groups:", 
      round(mean(df_analysis$christgrps_support, na.rm = TRUE) * 100, 1), "%\n")
  
  # Debug info
  cat("Non-missing christgrps_support values:", sum(!is.na(df_analysis$christgrps_support)), "\n")
  cat("Sample of christgrps_support values (should be 0s and 1s):\n")
  print(head(df_analysis$christgrps_support[!is.na(df_analysis$christgrps_support)], 20))
  cat("\n")
}
```

```{r}
# Check what we have to work with
religious_vars <- c("christgrps", "jewgrps", "islamgrps", "hindugrps", "atheistgrps")
religious_support_vars <- paste0(religious_vars, "_support")
available_religious_vars <- intersect(religious_support_vars, names(df_analysis))

cat("Available religious support variables:\n")
print(available_religious_vars)
cat("Length:", length(available_religious_vars), "\n\n")

cat("religion_clean variable exists:", "religion_clean" %in% names(df_analysis), "\n\n")

if(length(available_religious_vars) >= 3 && "religion_clean" %in% names(df_analysis)) {
  
  # Check religion_clean distribution
  cat("religion_clean distribution:\n")
  print(table(df_analysis$religion_clean, useNA = "ifany"))
  cat("\n")
  
  # Major religious groups for analysis
  major_religions <- c("Christian", "Catholic", "Protestant", "Jewish", "Muslim", "Atheist", "Agnostic")
  
  cat("Major religions we're looking for:\n")
  print(major_religions)
  cat("\n")
  
  # Check how many people are in major religions
  major_religion_count <- sum(df_analysis$religion_clean %in% major_religions, na.rm = TRUE)
  cat("People in major religions:", major_religion_count, "\n\n")
  
  # Create analysis dataset step by step
  analysis_cols <- c("religion_clean", available_religious_vars)
  cat("Analysis columns:\n")
  print(analysis_cols)
  cat("\n")
  
  # Step 1: Select columns
  alliance_data_step1 <- df_analysis[, analysis_cols]
  cat("After selecting columns:", nrow(alliance_data_step1), "rows\n")
  
  # Step 2: Filter to major religions
  alliance_data_step2 <- alliance_data_step1[alliance_data_step1$religion_clean %in% major_religions &
                                            !is.na(alliance_data_step1$religion_clean), ]
  cat("After filtering to major religions:", nrow(alliance_data_step2), "rows\n")
  
  # Step 3: Complete cases
  alliance_data_step3 <- alliance_data_step2[complete.cases(alliance_data_step2), ]
  cat("After removing incomplete cases:", nrow(alliance_data_step3), "rows\n")
  
  # Let's see what's in the religion_clean variable more carefully
  cat("\nDetailed religion_clean analysis:\n")
  religion_table <- table(df_analysis$religion_clean, useNA = "ifany")
  print(religion_table)
  
  # Check if the names match exactly
  unique_religions <- unique(df_analysis$religion_clean)
  unique_religions <- unique_religions[!is.na(unique_religions)]
  cat("\nActual unique religion values:\n")
  print(unique_religions)
  
  # Check which ones match our major_religions list
  cat("\nWhich religions match our list:\n")
  for(religion in major_religions) {
    matches <- sum(df_analysis$religion_clean == religion, na.rm = TRUE)
    cat(religion, ":", matches, "matches\n")
  }
  
} else {
  cat("Condition failed:\n")
  cat("- Available religious vars >= 3:", length(available_religious_vars) >= 3, "\n")
  cat("- religion_clean exists:", "religion_clean" %in% names(df_analysis), "\n")
}
```

## 9.2 Religious Group Alliance Patterns

```{r religious_group_alliance}
cat("=== RELIGIOUS GROUP ALLIANCE PATTERNS ===\n\n")

# Test Prediction 1: Religious in-group favoritism
religious_vars <- c("christgrps", "jewgrps", "islamgrps", "hindugrps", "atheistgrps")
religious_names <- c("christian", "jewish", "islamic", "hindu", "atheist")

# Check if we have the necessary variables
religious_support_vars <- paste0(religious_vars, "_support")
available_religious_vars <- intersect(religious_support_vars, names(df_analysis))

if(length(available_religious_vars) >= 3 && "religion_clean" %in% names(df_analysis)) {
  
  cat("Testing Alliance Theory Prediction 1: In-group favoritism in religious group funding\n\n")
  
  # Major religious groups for analysis
  major_religions <- c("christian", "catholic", "protestant", "jewish", "muslim", "atheist", "agnostic")
  
  # Create analysis dataset with religion and available support variables
  analysis_cols <- c("religion_clean", available_religious_vars)
  alliance_data <- df_analysis[, analysis_cols]
  
  # Filter to major religions and complete cases
  alliance_data <- alliance_data[alliance_data$religion_clean %in% major_religions &
                                !is.na(alliance_data$religion_clean), ]
  alliance_data <- alliance_data[complete.cases(alliance_data), ]
  
  cat("Sample size for religious alliance analysis:", nrow(alliance_data), "\n\n")
  
  if(nrow(alliance_data) > 500) {
    
    # Calculate support rates by religious affiliation
    alliance_summary <- data.frame()
    
    for(religion in major_religions) {
      if(sum(alliance_data$religion_clean == religion, na.rm = TRUE) > 30) {
        subset_data <- alliance_data[alliance_data$religion_clean == religion, ]
        
        summary_row <- data.frame(
          Religious_Group = religion,
          N = nrow(subset_data)
        )
        
        # Add support percentages for available variables
        if("christgrps_support" %in% names(subset_data)) {
          summary_row$Christian_Support <- round(mean(subset_data$christgrps_support, na.rm = TRUE) * 100, 1)
        }
        if("jewgrps_support" %in% names(subset_data)) {
          summary_row$Jewish_Support <- round(mean(subset_data$jewgrps_support, na.rm = TRUE) * 100, 1)
        }
        if("islamgrps_support" %in% names(subset_data)) {
          summary_row$Islamic_Support <- round(mean(subset_data$islamgrps_support, na.rm = TRUE) * 100, 1)
        }
        if("hindugrps_support" %in% names(subset_data)) {
          summary_row$Hindu_Support <- round(mean(subset_data$hindugrps_support, na.rm = TRUE) * 100, 1)
        }
        if("atheistgrps_support" %in% names(subset_data)) {
          summary_row$Atheist_Support <- round(mean(subset_data$atheistgrps_support, na.rm = TRUE) * 100, 1)
        }
        
        alliance_summary <- rbind(alliance_summary, summary_row)
      }
    }
    
    cat("Religious Group Funding Support by Religious Affiliation (% supporting):\n")
    print(alliance_summary)
    
    # Test for in-group favoritism with statistical significance
    cat("\n=== TESTING RELIGIOUS IN-GROUP FAVORITISM ===\n\n")
    
    # Christians (combine Christian, Catholic, Protestant) vs others
    if("christgrps_support" %in% names(alliance_data)) {
      christian_data <- alliance_data[alliance_data$religion_clean %in% 
                                    c("Christian", "Catholic", "Protestant"), ]
      
      if(nrow(christian_data) > 50) {
        christian_ingroup <- mean(christian_data$christgrps_support, na.rm = TRUE)
        
        # Compare to non-Christian religious groups
        non_christian_data <- alliance_data[!alliance_data$religion_clean %in% 
                                          c("Christian", "Catholic", "Protestant"), ]
        non_christian_support <- mean(non_christian_data$christgrps_support, na.rm = TRUE)
        
        # Statistical test
        christian_test <- t.test(christian_data$christgrps_support, 
                               non_christian_data$christgrps_support)
        
        cat("Christian In-group Favoritism Test:\n")
        cat("- Christians supporting Christian groups:", round(christian_ingroup * 100, 1), "%\n")
        cat("- Non-Christians supporting Christian groups:", round(non_christian_support * 100, 1), "%\n")
        cat("- Difference:", round((christian_ingroup - non_christian_support) * 100, 1), "percentage points\n")
        cat("- T-test p-value:", format.pval(christian_test$p.value), "\n")
        cat("- Christian N =", nrow(christian_data), ", Non-Christian N =", nrow(non_christian_data), "\n\n")
      }
    }
    
    # Atheists/Agnostics vs religious groups
    if("atheistgrps_support" %in% names(alliance_data)) {
      atheist_data <- alliance_data[alliance_data$religion_clean %in% c("Atheist", "Agnostic"), ]
      
      if(nrow(atheist_data) > 30) {
        atheist_ingroup <- mean(atheist_data$atheistgrps_support, na.rm = TRUE)
        
        # Compare to religious people
        religious_data <- alliance_data[!alliance_data$religion_clean %in% 
                                      c("Atheist", "Agnostic", "Nothing"), ]
        religious_support_atheist <- mean(religious_data$atheistgrps_support, na.rm = TRUE)
        
        # Statistical test
        atheist_test <- t.test(atheist_data$atheistgrps_support,
                             religious_data$atheistgrps_support)
        
        cat("Atheist In-group Favoritism Test:\n")
        cat("- Atheists supporting Atheist groups:", round(atheist_ingroup * 100, 1), "%\n")
        cat("- Religious people supporting Atheist groups:", round(religious_support_atheist * 100, 1), "%\n")
        cat("- Difference:", round((atheist_ingroup - religious_support_atheist) * 100, 1), "percentage points\n")
        cat("- T-test p-value:", format.pval(atheist_test$p.value), "\n")
        cat("- Atheist N =", nrow(atheist_data), ", Religious N =", nrow(religious_data), "\n\n")
      }
    }
    
    # Jewish in-group favoritism
    if("jewgrps_support" %in% names(alliance_data)) {
      jewish_data <- alliance_data[alliance_data$religion_clean == "jewish", ]
      
      if(nrow(jewish_data) > 20) {
        jewish_ingroup <- mean(jewish_data$jewgrps_support, na.rm = TRUE)
        
        non_jewish_data <- alliance_data[alliance_data$religion_clean != "jewish", ]
        non_jewish_support <- mean(non_jewish_data$jewgrps_support, na.rm = TRUE)
        
        cat("Jewish In-group Favoritism:\n")
        cat("- Jewish respondents supporting Jewish groups:", round(jewish_ingroup * 100, 1), "%\n")
        cat("- Non-Jewish respondents supporting Jewish groups:", round(non_jewish_support * 100, 1), "%\n")
        cat("- Difference:", round((jewish_ingroup - non_jewish_support) * 100, 1), "percentage points\n")
        cat("- Jewish N =", nrow(jewish_data), ", Non-Jewish N =", nrow(non_jewish_data), "\n\n")
      }
    }
    
  } else {
    cat("Insufficient data for religious alliance analysis (N =", nrow(alliance_data), ")\n\n")
  }
} else {
  cat("Insufficient religious variables or religion data for analysis\n\n")
}
```
## 9.3 Political Group Alliance Patterns

```{r political_alliance}
cat("\n=== POLITICAL GROUP ALLIANCE PATTERNS ===\n\n")

# Test political alliance patterns
political_vars <- c("gopgrps", "demgrps", "consgrps", "libgrps")
political_names <- c("Republican", "Democratic", "Conservative", "Liberal")

political_support_vars <- paste0(political_vars, "_support")
available_political_vars <- intersect(political_support_vars, names(df_analysis))

if(length(available_political_vars) >= 2 && "ideology_clean" %in% names(df_analysis)) {
  
  cat("Testing Alliance Theory Prediction 2: Political in-group favoritism\n\n")
  
  # Create analysis dataset
  analysis_cols <- c("ideology_clean", available_political_vars)
  ideology_alliance <- df_analysis[, analysis_cols]
  ideology_alliance <- ideology_alliance[!is.na(ideology_alliance$ideology_clean), ]
  ideology_alliance <- ideology_alliance[complete.cases(ideology_alliance), ]
  
  cat("Sample size for political alliance analysis:", nrow(ideology_alliance), "\n\n")
  
  if(nrow(ideology_alliance) > 500) {
    
    # Calculate support by ideology
    ideology_summary <- data.frame()
    
    # Get unique ideologies with sufficient sample sizes
    ideology_counts <- table(ideology_alliance$ideology_clean)
    sufficient_ideologies <- names(ideology_counts[ideology_counts >= 30])
    
    for(ideo in sufficient_ideologies) {
      subset_data <- ideology_alliance[ideology_alliance$ideology_clean == ideo, ]
      
      summary_row <- data.frame(
        Political_Ideology = ideo,
        N = nrow(subset_data)
      )
      
      # Add support percentages for available variables
      if("gopgrps_support" %in% names(subset_data)) {
        summary_row$Republican_Support <- round(mean(subset_data$gopgrps_support, na.rm = TRUE) * 100, 1)
      }
      if("demgrps_support" %in% names(subset_data)) {
        summary_row$Democratic_Support <- round(mean(subset_data$demgrps_support, na.rm = TRUE) * 100, 1)
      }
      if("consgrps_support" %in% names(subset_data)) {
        summary_row$Conservative_Support <- round(mean(subset_data$consgrps_support, na.rm = TRUE) * 100, 1)
      }
      if("libgrps_support" %in% names(subset_data)) {
        summary_row$Liberal_Support <- round(mean(subset_data$libgrps_support, na.rm = TRUE) * 100, 1)
      }
      
      ideology_summary <- rbind(ideology_summary, summary_row)
    }
    
    cat("Political Group Support by Ideology (% supporting):\n")
    print(ideology_summary)
    
    # Test for political in-group favoritism
    cat("\n=== TESTING POLITICAL IN-GROUP FAVORITISM ===\n\n")
    
    # Conservative in-group favoritism (if variables available)
    if(all(c("gopgrps_support", "consgrps_support", "demgrps_support", "libgrps_support") %in% names(ideology_alliance))) {
      
      conservative_ideologies <- c("Somewhat conservative", "Very conservative", "Slightly conservative")
      conservative_data <- ideology_alliance[ideology_alliance$ideology_clean %in% conservative_ideologies, ]
      
      if(nrow(conservative_data) > 50) {
        # Conservative in-group support (average of GOP and Conservative groups)
        cons_ingroup <- rowMeans(conservative_data[, c("gopgrps_support", "consgrps_support")], na.rm = TRUE)
        # Conservative out-group opposition (average of Dem and Liberal groups)  
        cons_outgroup <- rowMeans(conservative_data[, c("demgrps_support", "libgrps_support")], na.rm = TRUE)
        
        cons_test <- t.test(cons_ingroup, cons_outgroup, paired = TRUE)
        cons_bias <- mean(cons_ingroup, na.rm = TRUE) - mean(cons_outgroup, na.rm = TRUE)
        
        cat("Conservative In-group Favoritism:\n")
        cat("- Conservative/GOP group support:", round(mean(cons_ingroup, na.rm = TRUE) * 100, 1), "%\n")
        cat("- Liberal/Democratic group support:", round(mean(cons_outgroup, na.rm = TRUE) * 100, 1), "%\n")
        cat("- In-group bias:", round(cons_bias * 100, 1), "percentage points\n")
        cat("- Paired t-test p-value:", format.pval(cons_test$p.value), "\n")
        cat("- N =", nrow(conservative_data), "\n\n")
      }
      
      # Liberal in-group favoritism
      liberal_ideologies <- c("Somewhat liberal", "Very liberal", "Slightly liberal", "Democratic Socialist")
      liberal_data <- ideology_alliance[ideology_alliance$ideology_clean %in% liberal_ideologies, ]
      
      if(nrow(liberal_data) > 50) {
        # Liberal in-group support (average of Dem and Liberal groups)
        lib_ingroup <- rowMeans(liberal_data[, c("demgrps_support", "libgrps_support")], na.rm = TRUE)
        # Liberal out-group opposition (average of GOP and Conservative groups)
        lib_outgroup <- rowMeans(liberal_data[, c("gopgrps_support", "consgrps_support")], na.rm = TRUE)
        
        lib_test <- t.test(lib_ingroup, lib_outgroup, paired = TRUE)
        lib_bias <- mean(lib_ingroup, na.rm = TRUE) - mean(lib_outgroup, na.rm = TRUE)
        
        cat("Liberal In-group Favoritism:\n")
        cat("- Liberal/Democratic group support:", round(mean(lib_ingroup, na.rm = TRUE) * 100, 1), "%\n")
        cat("- Conservative/GOP group support:", round(mean(lib_outgroup, na.rm = TRUE) * 100, 1), "%\n")
        cat("- In-group bias:", round(lib_bias * 100, 1), "percentage points\n")
        cat("- Paired t-test p-value:", format.pval(lib_test$p.value), "\n")
        cat("- N =", nrow(liberal_data), "\n\n")
      }
    } else {
      cat("Insufficient political group variables for in-group bias analysis\n\n")
    }
    
  } else {
    cat("Insufficient data for political alliance analysis (N =", nrow(ideology_alliance), ")\n\n")
  }
} else {
  cat("Insufficient political variables or ideology data for analysis\n\n")
}

```

## 9.4 Issue-Specific Alliance Testing

```{r issue_specific_alliance}
cat("\n=== ISSUE-SPECIFIC ALLIANCE PATTERNS ===\n\n")

# Test multiple issue-specific alliance patterns
alliance_issue_vars <- c("blmgrps", "israelgrps", "palestinegrps", "asiangrps", "blkgrps", "hispgrps", "lgbtqgrps")
alliance_support_vars <- paste0(alliance_issue_vars, "_support")
available_alliance_vars <- intersect(alliance_support_vars, names(df_analysis))

cat("Available alliance variables:", paste(available_alliance_vars, collapse = ", "), "\n\n")

if(length(available_alliance_vars) >= 2) {
  
  cat("Testing Alliance Theory Prediction 3: Consistent ally/rival patterns across issues\n\n")
  
  # Create analysis dataset
  alliance_cols <- c("ideology_clean", available_alliance_vars)
  alliance_cors <- df_analysis[, alliance_cols]
  alliance_cors <- alliance_cors[complete.cases(alliance_cors), ]
  
  cat("Sample size for issue alliance analysis:", nrow(alliance_cors), "\n\n")
  
  if(nrow(alliance_cors) > 500) {
    
    # Calculate correlations between available alliance variables
    if(length(available_alliance_vars) >= 2) {
      cat("Correlations between group support patterns:\n")
      cor_matrix <- cor(alliance_cors[, available_alliance_vars, drop = FALSE], use = "complete.obs")
      print(round(cor_matrix, 3))
      cat("\n")
    }
    
    # Test specific alliance predictions
    cat("=== ALLIANCE PATTERN ANALYSIS ===\n\n")
    
    # BLM-Palestine alliance pattern (if both available)
    if(all(c("blmgrps_support", "palestinegrps_support") %in% names(alliance_cors))) {
      blm_palestine_cor <- cor(alliance_cors$blmgrps_support, alliance_cors$palestinegrps_support, use = "complete.obs")
      blm_palestine_test <- cor.test(alliance_cors$blmgrps_support, alliance_cors$palestinegrps_support)
      
      cat("BLM-Palestine Alliance Correlation:\n")
      cat("- Correlation:", round(blm_palestine_cor, 3), "\n")
      cat("- P-value:", format.pval(blm_palestine_test$p.value), "\n")
      cat("- N =", sum(complete.cases(alliance_cors$blmgrps_support, alliance_cors$palestinegrps_support)), "\n\n")
    }
    
    # Israel-Palestine opposition pattern (if both available)
    if(all(c("israelgrps_support", "palestinegrps_support") %in% names(alliance_cors))) {
      israel_palestine_cor <- cor(alliance_cors$israelgrps_support, alliance_cors$palestinegrps_support, use = "complete.obs")
      israel_palestine_test <- cor.test(alliance_cors$israelgrps_support, alliance_cors$palestinegrps_support)
      
      cat("Israel-Palestine Opposition Pattern:\n")
      cat("- Correlation:", round(israel_palestine_cor, 3), "\n")
      cat("- P-value:", format.pval(israel_palestine_test$p.value), "\n")
      cat("- N =", sum(complete.cases(alliance_cors$israelgrps_support, alliance_cors$palestinegrps_support)), "\n\n")
    }
    
    # Racial/ethnic coalition patterns
    if(all(c("blkgrps_support", "hispgrps_support") %in% names(alliance_cors))) {
      black_hispanic_cor <- cor(alliance_cors$blkgrps_support, alliance_cors$hispgrps_support, use = "complete.obs")
      black_hispanic_test <- cor.test(alliance_cors$blkgrps_support, alliance_cors$hispgrps_support)
      
      cat("Black-Hispanic Coalition Pattern:\n")
      cat("- Correlation:", round(black_hispanic_cor, 3), "\n")
      cat("- P-value:", format.pval(black_hispanic_test$p.value), "\n")
      cat("- N =", sum(complete.cases(alliance_cors$blkgrps_support, alliance_cors$hispgrps_support)), "\n\n")
    }
    
    # Progressive coalition (BLM + LGBTQ)
    if(all(c("blmgrps_support", "lgbtqgrps_support") %in% names(alliance_cors))) {
      blm_lgbtq_cor <- cor(alliance_cors$blmgrps_support, alliance_cors$lgbtqgrps_support, use = "complete.obs")
      blm_lgbtq_test <- cor.test(alliance_cors$blmgrps_support, alliance_cors$lgbtqgrps_support)
      
      cat("BLM-LGBTQ Progressive Coalition:\n")
      cat("- Correlation:", round(blm_lgbtq_cor, 3), "\n")
      cat("- P-value:", format.pval(blm_lgbtq_test$p.value), "\n")
      cat("- N =", sum(complete.cases(alliance_cors$blmgrps_support, alliance_cors$lgbtqgrps_support)), "\n\n")
    }
    
    # Asian-Black coalition pattern
    if(all(c("asiangrps_support", "blkgrps_support") %in% names(alliance_cors))) {
      asian_black_cor <- cor(alliance_cors$asiangrps_support, alliance_cors$blkgrps_support, use = "complete.obs")
      asian_black_test <- cor.test(alliance_cors$asiangrps_support, alliance_cors$blkgrps_support)
      
      cat("Asian-Black Coalition Pattern:\n")
      cat("- Correlation:", round(asian_black_cor, 3), "\n")
      cat("- P-value:", format.pval(asian_black_test$p.value), "\n")
      cat("- N =", sum(complete.cases(alliance_cors$asiangrps_support, alliance_cors$blkgrps_support)), "\n\n")
    }
    
    # Alliance patterns by ideology
    if("ideology_clean" %in% names(alliance_cors) && length(available_alliance_vars) >= 1) {
      
      alliance_by_ideology <- data.frame()
      ideology_counts <- table(alliance_cors$ideology_clean)
      sufficient_ideologies <- names(ideology_counts[ideology_counts >= 30])
      
      for(ideo in sufficient_ideologies) {
        subset_data <- alliance_cors[alliance_cors$ideology_clean == ideo, ]
        
        summary_row <- data.frame(
          Political_Ideology = ideo,
          N = nrow(subset_data)
        )
        
        # Add support percentages for available variables
        if("blmgrps_support" %in% names(subset_data)) {
          summary_row$BLM_Support <- round(mean(subset_data$blmgrps_support, na.rm = TRUE) * 100, 1)
        }
        if("israelgrps_support" %in% names(subset_data)) {
          summary_row$Israel_Support <- round(mean(subset_data$israelgrps_support, na.rm = TRUE) * 100, 1)
        }
        if("palestinegrps_support" %in% names(subset_data)) {
          summary_row$Palestine_Support <- round(mean(subset_data$palestinegrps_support, na.rm = TRUE) * 100, 1)
        }
        if("lgbtqgrps_support" %in% names(subset_data)) {
          summary_row$LGBTQ_Support <- round(mean(subset_data$lgbtqgrps_support, na.rm = TRUE) * 100, 1)
        }
        if("asiangrps_support" %in% names(subset_data)) {
          summary_row$Asian_Support <- round(mean(subset_data$asiangrps_support, na.rm = TRUE) * 100, 1)
        }
        if("blkgrps_support" %in% names(subset_data)) {
          summary_row$Black_Support <- round(mean(subset_data$blkgrps_support, na.rm = TRUE) * 100, 1)
        }
        if("hispgrps_support" %in% names(subset_data)) {
          summary_row$Hispanic_Support <- round(mean(subset_data$hispgrps_support, na.rm = TRUE) * 100, 1)
        }
        
        alliance_by_ideology <- rbind(alliance_by_ideology, summary_row)
      }
      
      cat("Issue-based group support by political ideology:\n")
      print(alliance_by_ideology)
      cat("\n")
    }
    
  } else {
    cat("Insufficient data for issue alliance analysis (N =", nrow(alliance_cors), ")\n\n")
  }
} else {
  cat("Insufficient issue-specific group variables for alliance analysis\n\n")
}
```

## 9.5 Inconsistent Principle Application

```{r inconsisten_principle}
# Test speaker tolerance inconsistencies
speaker_vars <- c("spktrans", "spkabortion", "spkblm", "spkchurch", "spkpolice", "spkchildren")
speaker_names <- c("Transgender", "Abortion", "BLM", "Church", "Police", "Children")

# Check which speaker variables actually exist
available_speaker_vars <- intersect(speaker_vars, names(df_analysis))
cat("Available speaker variables:", paste(available_speaker_vars, collapse = ", "), "\n\n")

if(length(available_speaker_vars) >= 4) {
  
  # Create tolerance scores - handle factor variables properly
  tolerance_vars <- character(length(available_speaker_vars))
  
  cat("Creating tolerance variables from factor data:\n")
  for(i in 1:length(available_speaker_vars)) {
    var <- available_speaker_vars[i]
    tolerance_var <- paste0(var, "_tolerance")
    tolerance_vars[i] <- tolerance_var
    
    # Check the distribution first
    cat("Original", var, "distribution:\n")
    print(table(df_analysis[[var]], useNA = "ifany"))
    
    # Convert factor to numeric tolerance scale
    # "Definitely should allow" = most tolerant (4)
    # "Probably should allow" = somewhat tolerant (3) 
    # "Probably should not allow" = somewhat intolerant (2)
    # "Definitely should not allow" = least tolerant (1)
    
    df_analysis[[tolerance_var]] <- case_when(
      df_analysis[[var]] == "Definitely should allow this speaker" ~ 4,
      df_analysis[[var]] == "Probably should allow this speaker" ~ 3,
      df_analysis[[var]] == "Probably should not allow this speaker" ~ 2,
      df_analysis[[var]] == "Definitely should not allow this speaker" ~ 1,
      TRUE ~ NA_real_
    )
    
    cat("Created", tolerance_var, "- sample values:\n")
    print(head(df_analysis[[tolerance_var]][!is.na(df_analysis[[tolerance_var]])], 10))
    cat("Mean tolerance:", round(mean(df_analysis[[tolerance_var]], na.rm = TRUE), 2), "\n\n")
  }
  
  # Analyze by ideology using base R
  analysis_cols <- c("ideology_clean", tolerance_vars)
  speaker_tolerance <- df_analysis[, analysis_cols]
  speaker_tolerance <- speaker_tolerance[!is.na(speaker_tolerance$ideology_clean), ]
  speaker_tolerance <- speaker_tolerance[complete.cases(speaker_tolerance), ]
  
  cat("Sample size for speaker tolerance analysis:", nrow(speaker_tolerance), "\n\n")
  
  if(nrow(speaker_tolerance) > 1000) {
    
    # Calculate tolerance by ideology
    tolerance_summary <- data.frame()
    
    ideology_counts <- table(speaker_tolerance$ideology_clean)
    sufficient_ideologies <- names(ideology_counts[ideology_counts >= 30])
    
    for(ideo in sufficient_ideologies) {
      subset_data <- speaker_tolerance[speaker_tolerance$ideology_clean == ideo, ]
      
      summary_row <- data.frame(
        ideology_clean = ideo,
        N = nrow(subset_data)
      )
      
      # Add tolerance scores for available variables
      for(tol_var in tolerance_vars) {
        if(tol_var %in% names(subset_data)) {
          col_name <- gsub("_tolerance", "_Tolerance", tol_var)
          col_name <- gsub("spk", "", col_name)
          col_name <- paste0(toupper(substring(col_name, 1, 1)), substring(col_name, 2))
          summary_row[[col_name]] <- round(mean(subset_data[[tol_var]], na.rm = TRUE), 2)
        }
      }
      
      tolerance_summary <- rbind(tolerance_summary, summary_row)
    }
    
    cat("Speaker tolerance by ideology (1=least tolerant, 4=most tolerant):\n")
    print(tolerance_summary)
    
    # Test for inconsistent application of "free speech" principle
    cat("\n=== TESTING FOR INCONSISTENT PRINCIPLE APPLICATION ===\n\n")
    
    # Conservatives: compare tolerance for ally vs rival speakers
    conservative_ideologies <- c("Somewhat conservative", "Very conservative", "Slightly conservative")
    conservative_tolerance <- speaker_tolerance[speaker_tolerance$ideology_clean %in% conservative_ideologies, ]
    
    if(nrow(conservative_tolerance) > 50) {
      
      # Conservative ally speakers (church, police if available)
      ally_vars <- intersect(c("spkchurch_tolerance", "spkpolice_tolerance"), names(conservative_tolerance))
      # Conservative rival speakers (trans, BLM if available)  
      rival_vars <- intersect(c("spktrans_tolerance", "spkblm_tolerance"), names(conservative_tolerance))
      
      if(length(ally_vars) > 0 && length(rival_vars) > 0) {
        cons_ally_tolerance <- rowMeans(conservative_tolerance[, ally_vars, drop = FALSE], na.rm = TRUE)
        cons_rival_tolerance <- rowMeans(conservative_tolerance[, rival_vars, drop = FALSE], na.rm = TRUE)
        
        cons_gap <- mean(cons_ally_tolerance, na.rm = TRUE) - mean(cons_rival_tolerance, na.rm = TRUE)
        cons_test <- t.test(cons_ally_tolerance, cons_rival_tolerance, paired = TRUE)
        
        cat("Conservative tolerance gap analysis:\n")
        cat("- Ally speakers (church/police):", round(mean(cons_ally_tolerance, na.rm = TRUE), 3), "\n")
        cat("- Rival speakers (trans/BLM):", round(mean(cons_rival_tolerance, na.rm = TRUE), 3), "\n")
        cat("- Tolerance gap (allies vs rivals):", round(cons_gap, 3), "\n")
        cat("- Paired t-test p-value:", format.pval(cons_test$p.value), "\n")
        cat("- N =", nrow(conservative_tolerance), "\n\n")
      }
    }
    
    # Liberals: compare tolerance for ally vs rival speakers
    liberal_ideologies <- c("Somewhat liberal", "Very liberal", "Slightly liberal", "Democratic Socialist")
    liberal_tolerance <- speaker_tolerance[speaker_tolerance$ideology_clean %in% liberal_ideologies, ]
    
    if(nrow(liberal_tolerance) > 50) {
      
      # Liberal ally speakers (trans, BLM if available)
      ally_vars <- intersect(c("spktrans_tolerance", "spkblm_tolerance"), names(liberal_tolerance))
      # Liberal rival speakers (church, police if available)
      rival_vars <- intersect(c("spkchurch_tolerance", "spkpolice_tolerance"), names(liberal_tolerance))
      
      if(length(ally_vars) > 0 && length(rival_vars) > 0) {
        lib_ally_tolerance <- rowMeans(liberal_tolerance[, ally_vars, drop = FALSE], na.rm = TRUE)
        lib_rival_tolerance <- rowMeans(liberal_tolerance[, rival_vars, drop = FALSE], na.rm = TRUE)
        
        lib_gap <- mean(lib_ally_tolerance, na.rm = TRUE) - mean(lib_rival_tolerance, na.rm = TRUE)
        lib_test <- t.test(lib_ally_tolerance, lib_rival_tolerance, paired = TRUE)
        
        cat("Liberal tolerance gap analysis:\n")
        cat("- Ally speakers (trans/BLM):", round(mean(lib_ally_tolerance, na.rm = TRUE), 3), "\n")
        cat("- Rival speakers (church/police):", round(mean(lib_rival_tolerance, na.rm = TRUE), 3), "\n")
        cat("- Tolerance gap (allies vs rivals):", round(lib_gap, 3), "\n")
        cat("- Paired t-test p-value:", format.pval(lib_test$p.value), "\n")
        cat("- N =", nrow(liberal_tolerance), "\n\n")
      }
    }
    
  } else {
    cat("Insufficient data for speaker tolerance analysis (N =", nrow(speaker_tolerance), ")\n\n")
  }
  
} else {
  cat("Insufficient speaker tolerance variables available for inconsistent principle analysis\n")
  cat("Available variables:", paste(available_speaker_vars, collapse = ", "), "\n")
  cat("Need at least 4 variables for robust analysis\n\n")
}
```


# 10. Summary of Key Findings

## 10.1 Results

### Core Findings: Self-Censorship and Protest Tolerance Relationships

This analysis of 58,807 college students first examined the  relationships between self-censorship behaviors and tolerance for protest tactics through an individual question-level approach, revealing nuanced patterns that would be obscured by composite scoring methods. The investigation focused on four distinct self-censorship contexts and three categories of protest tolerance, providing unprecedented granularity in understanding campus free speech dynamics.

### Self-Censorship and Protest Tolerance Correlations

The core research question revealed small but statistically significant positive correlations between certain forms of self-censorship and tolerance for disruptive protest tactics. General self-censorship demonstrated the strongest associations with protest tolerance, showing positive correlations with tolerance for shouting down speakers (r = 0.033, p < 0.001, N = 58,807), blocking access to events (r = 0.028, p < 0.001, N = 58,807), and using violence against speakers (r = 0.009, p = 0.028, N = 58,807). These findings suggest that students who report constraining their own expression may simultaneously be more accepting of censorious behaviors by others.

However, the relationship patterns varied substantially across different self-censorship contexts, revealing important nuances in campus expression dynamics. Self-censorship with students showed weaker but similar directional patterns (r = 0.022 for shouting down, r = 0.014 for blocking, r = 0.006 for violence). Most notably, self-censorship with professors exhibited contrasting patterns, showing negative correlations with blocking (r = -0.018, p < 0.001) and violence tolerance (r = -0.022, p < 0.001), while maintaining a small positive correlation with shouting down tolerance (r = -0.007, p = 0.081). Self-censorship in classroom settings showed the most negative pattern, with significant negative correlations with both blocking (r = -0.012, p < 0.01) and violence tolerance (r = -0.014, p < 0.001).

### Political Ideology and Expression Patterns
Political ideology emerged as the strongest predictor of both self-censorship behaviors and protest tolerance, with highly significant omnibus effects across all measures (F-statistics ranging from 17.31 to 89.84, all p < 0.001). The ideological patterns revealed systematic differences that align with alliance theory predictions about group-based political preferences.

For self-censorship behaviors, conservative students consistently reported lower levels across all contexts. Very conservative students showed the lowest general self-censorship (M = 2.97, SD = 1.17), while very liberal students reported higher levels (M = 3.11, SD = 1.05). This pattern held across self-censorship with students, professors, and in classroom settings, suggesting that conservative students either experience less pressure to self-censor or are more willing to express potentially controversial views despite social costs.

Protest tolerance patterns revealed more dramatic ideological differences, particularly for tolerance of violence against speakers. Very liberal students showed the lowest tolerance for violence (M = 1.57, SD = 1.97), while very conservative students showed higher tolerance (M = 2.85, SD = 2.99). Interestingly, this pattern was reversed for tolerance of shouting down and blocking, where liberal students showed greater tolerance for these less severe forms of protest disruption.

### Alliance Theory Validation: Group-Based Political Preferences
The analysis provided strong empirical support for alliance theory predictions through examination of religious group funding preferences and speaker tolerance patterns. Religious group funding preferences demonstrated substantial systematic variation by respondents' own religious affiliation, with chi-square statistics exceeding 1561 across all comparisons (all p < 0.001). Protestant students showed strong support for funding Christian groups while opposing Muslim group funding, Catholic students showed similar but more moderate patterns, and non-religious students demonstrated inverse preferences.

### Speaker Tolerance and Alliance Patterns
Analysis of tolerance for specific types of speakers revealed clear alliance-based patterns consistent with Pinsof, Sears, and Haselton's (2023) alliance theory framework. Conservative students showed systematically higher tolerance for speakers aligned with their political coalition (church leaders, police representatives) while displaying lower tolerance for speakers associated with rival political groups (transgender rights activists, Black Lives Matter speakers). Liberal students demonstrated the mirror-image pattern, with higher tolerance for progressive speakers and lower tolerance for conservative-aligned speakers.

The magnitude of these alliance-based tolerance gaps was substantial and statistically significant. Conservative students (combining somewhat and very conservative) showed a tolerance gap of -0.294 between ally speakers (church/police: M = 2.299) and rival speakers (transgender/BLM: M = 2.593), t-test p < 0.001, N = 11,618. Liberal students (combining somewhat and very liberal) demonstrated an even larger tolerance gap of -0.731 between ally speakers (transgender/BLM: M = 1.746) and rival speakers (church/police: M = 2.477), t-test p < 0.001, N = 30,458.

### Issue-Specific Alliance Patterns
The analysis revealed strong correlations between support patterns across different political issues, providing evidence for coherent alliance structures rather than principled ideological consistency. Support for Black Lives Matter groups correlated strongly with support for Palestinian groups (r = 0.711), LGBTQ groups (r = 0.745), and other progressive-coded identity groups. Support for Israeli groups showed weaker correlations with these progressive groups but stronger correlations with each other and conservative-coded causes.

### Mental Health and Demographic Correlates
Mental health variables showed complex and sometimes counterintuitive relationships with self-censorship behaviors. Stress demonstrated consistent negative correlations with all self-censorship measures (r = -0.037 to -0.048, all p < 0.05), contradicting expectations that psychological distress would increase behavioral inhibition. Depression showed mixed patterns, with positive correlations with self-censorship around students (r = 0.022, p = 0.016) but negative correlations with general self-censorship (r = -0.015, p = 0.108). Anxiety and loneliness showed minimal correlations with self-censorship behaviors (|r| < 0.02).

Religious affiliation analysis revealed significant but modest effects on self-censorship (F = 4.14 to 5.43, p < 0.001), with agnostic students reporting the highest general self-censorship levels (M = 3.14, SD = 1.05) and Protestant students the lowest (M = 3.01, SD = 1.13). Cohort effects emerged across graduation years, with seniors (Class of 2024) reporting higher self-censorship (M = 3.11, SD = 1.10) than first-years (Class of 2027: M = 3.05, SD = 1.09), F = 8.43, p < 0.001.

Institution type showed no significant differences between public and private schools (F = 0.835, p = 0.361), with nearly identical means (M = 3.08 for both). Socioeconomic status showed significant but small effects (F = 5.488, p < 0.001), with middle-class and upper-middle-class students reporting slightly higher self-censorship.


## 10.2 Discussion

These findings provide the first large-scale empirical validation of alliance theory principles in the campus free speech context, demonstrating that political expression patterns are fundamentally shaped by group allegiances rather than consistent principled commitments to free speech values. The systematic tolerance gaps between ally and rival speakers across the ideological spectrum directly support Pinsof, Sears, and Haselton's (2023) core theoretical prediction that political attitudes derive from coalition maintenance rather than abstract moral principles.

### The Paradox of Self-Censorship and Protest Tolerance
The positive correlations between general self-censorship and tolerance for disruptive protest tactics present a significant theoretical puzzle that challenges conventional free speech frameworks. Traditional liberal theory would predict that individuals who value open expression (evidenced by refusing to self-censor) would simultaneously oppose censorious tactics by others. Instead, these data suggest a more complex dynamic where self-censorship and tolerance for others' censorious behaviors may be complementary rather than opposing phenomena.

This pattern aligns with alliance theory's prediction that apparent contradictions in political beliefs reflect strategic support for different tactics depending on their utility for one's political coalition. Students who self-censor may do so not from principled commitment to civility, but from tactical recognition that their views would be costly to express in the current campus environment. Simultaneously, these same students may support disruptive tactics when deployed against speakers representing rival political coalitions, viewing such tactics as legitimate tools for advancing their side's interests.

The differential patterns across self-censorship contexts provide further evidence for this alliance-based interpretation. The negative correlations between self-censorship with professors and tolerance for violence suggest that students who feel comfortable expressing themselves to authority figures may be more committed to institutionally sanctioned forms of discourse. Conversely, students who self-censor in hierarchical relationships may be more supportive of extra-institutional tactics for silencing opponents.

### Political Identity as the Primary Driver
The dominance of political ideology as a predictor of both self-censorship and protest tolerance patterns, combined with the systematic alliance-based speaker tolerance gaps, provides strong evidence that campus free speech issues are fundamentally questions of political identity rather than principled commitments to expression values. The fact that both conservative and liberal students demonstrate substantial tolerance gaps—favoring allies while opposing rivals—undermines narratives that frame campus free speech as a conflict between pro- and anti-free speech factions.

Instead, these patterns suggest that campus expression conflicts represent standard political competition, where each side supports expression freedoms for allies while seeking to constrain expression by rivals. This interpretation explains the seemingly hypocritical pattern where the same students who claim to value free speech simultaneously support disrupting speakers from opposing political coalitions.

### Alliance Theory and Campus Policy Implications
The validation of alliance theory predictions has profound implications for campus policy and intervention design. Traditional approaches that frame free speech as a matter of individual rights or institutional culture may be fundamentally misguided if expression patterns are primarily driven by group competition dynamics. Interventions that attempt to promote "free speech values" without addressing underlying political polarization may fail because they misdiagnose the core problem.

The strong correlations between support for different political causes (r = 0.7+ between various progressive groups) suggest that campus political attitudes are organized around coherent alliance structures rather than issue-specific principles. This finding implies that conflicts over campus speakers, funding allocations, and expression policies should be understood as manifestations of broader political coalition competition rather than isolated disputes about specific speakers or events.

### Mental Health and Expression: Reconsidering Causal Assumptions
The counterintuitive negative correlation between stress and self-censorship challenges common assumptions about the psychological drivers of expression restraint. Rather than psychological distress leading to behavioral inhibition, these patterns may reflect reverse causality where engaging in self-censorship reduces stress by avoiding social conflict. Alternatively, stressed students may become less sensitive to social pressure and more willing to express controversial views despite potential costs.

This finding has important implications for campus mental health initiatives and their relationship to expression climates. If self-censorship serves a stress-reduction function for some students, interventions that simply encourage more open expression without addressing underlying campus political dynamics may inadvertently increase psychological distress among vulnerable populations.

### Institutional Context and Democratic Implications

The absence of significant differences between public and private institutions suggests that campus expression climates are driven more by student body composition and political culture than by formal governance structures or funding sources. This finding challenges policy proposals that focus primarily on institutional incentives (such as funding mechanisms or legal requirements) rather than addressing the underlying political dynamics that drive expression conflicts.

The cohort effects showing declining self-censorship among newer students may reflect generational differences in political expression norms, adaptation effects where students become more constrained over time, or period effects related to changing campus climates. Understanding these temporal dynamics is crucial for predicting how campus expression patterns may evolve and for designing effective long-term interventions.

### Limitations and Future Directions
Several limitations qualify these findings and suggest directions for future research. The cross-sectional design prevents causal inference about the relationships between self-censorship and protest tolerance, leaving open questions about whether these attitudes co-develop or whether one causes the other. The individual question approach, while preserving important nuances, may underestimate the coherence of underlying attitudes that composite measures would capture.

The self-report nature of the data may be subject to social desirability bias, particularly for politically sensitive topics like tolerance for violence. Additionally, the sample, while large and diverse, comes primarily from students who chose to participate in FIRE surveys and may not represent the full range of campus opinion, potentially undersampling the most politically disengaged students.

Future research should employ longitudinal designs to examine how campus expression attitudes develop over time and in response to specific events or interventions. Experimental studies could test causal mechanisms linking self-censorship to protest tolerance and examine whether interventions targeting one domain affect the other. Qualitative research could illuminate the psychological processes underlying the counterintuitive relationships between stress and self-censorship, while cross-institutional comparisons could identify campus-level factors that promote or constrain open expression environments.

### Broader Implications for Democratic Discourse
These findings extend beyond campus contexts to illuminate broader challenges facing democratic discourse in polarized societies. The evidence that expression tolerance is primarily driven by political allegiance rather than principled commitment to free speech suggests that First Amendment protections and liberal democratic norms may be more fragile than commonly assumed. If citizens primarily support expression rights for political allies while seeking to constrain opponents, democratic institutions may face increasing pressure as political polarization intensifies.

The systematic nature of alliance-based tolerance patterns across the ideological spectrum suggests that effective interventions must address the fundamental drivers of political polarization rather than focusing solely on symptoms like campus speaker disruptions or self-censorship. This analysis points toward the need for approaches that either reduce the intensity of political competition or develop institutional mechanisms that can function effectively despite persistent group-based loyalties that override abstract democratic values.

Understanding campus free speech through an alliance theory lens ultimately reveals that debates about expression rights, trigger warnings, safe spaces, and speaker policies are manifestations of deeper conflicts about political power and group status in American society. Addressing these challenges will require interventions that grapple with the fundamental nature of political coalition competition rather than assuming that appeals to shared democratic values will override group-based loyalties.

---

QED
